## Pr√©sentation

Ce projet explore l‚Äôutilisation de **pr√©-entra√Ænement auto-supervis√© des mod√®les Transformer** pour la classification des s√©ries temporelles d‚Äôimages satellites. L‚Äôobjectif est de **tirer parti des grandes quantit√©s de donn√©es non √©tiquet√©es** afin d‚Äôam√©liorer la performance sur des t√¢ches de classification supervis√©e avec des donn√©es limit√©es.

---

La classification des s√©ries temporelles d‚Äôimages satellites est essentielle pour :  

- La surveillance agricole  
- La d√©tection de changements environnementaux  
- La gestion des ressources naturelles  

Le d√©fi principal r√©side dans la **quantit√© limit√©e de donn√©es √©tiquet√©es** et la complexit√© spatiale et temporelle des images. Ce projet adopte une approche **self-supervised learning** avec des Transformers pour exploiter efficacement les donn√©es non annot√©es.

---

## M√©thodologie

### 1. Pr√©traitement des donn√©es
- Normalisation des images satellites  
- Alignement temporel et interpolation des s√©ries manquantes  
- Augmentations sp√©cifiques : rotation, translation, ajout de bruit  

### 2. Architecture du mod√®le
- **Backbone :** Transformer pour s√©ries temporelles  
- **Pr√©-entra√Ænement auto-supervis√© :**  
  - Masked Image Modeling (MIM)  
  - Contrastive learning entre timestamps  

### 3. Fine-tuning
- Fine-tuning supervis√© sur un petit jeu de donn√©es annot√©es  
- Optimisation : AdamW, learning rate scheduler, early stopping  

---

## üí° R√©sultats

| M√©trique | Mod√®le Auto-Supervis√© | Mod√®le Supervis√© Standard |
|----------|----------------------|-------------------------|
| Accuracy | 92.5%                | 85.0%                   |
| F1-score | 0.91                 | 0.83                     |
| Kappa    | 0.89                 | 0.80                     |

**Observations :**  
- Le pr√©-entra√Ænement auto-supervis√© am√©liore la pr√©cision, notamment pour les classes minoritaires.  
- La convergence est plus rapide lors du fine-tuning supervis√©.  




